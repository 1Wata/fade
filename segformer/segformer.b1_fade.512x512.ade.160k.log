2022-03-09 20:06:03,122 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]
CUDA available: True
GPU 0,1: RTX A6000
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.1.TC455_06.29069683_0
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.9.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.10.0
OpenCV: 4.5.3
MMCV: 1.2.7
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.1
MMSegmentation: 0.11.0+
------------------------------------------------------------

2022-03-09 20:06:03,122 - mmseg - INFO - Distributed training: False
2022-03-09 20:06:03,470 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
find_unused_parameters = True
model = dict(
    type='EncoderDecoder',
    pretrained='pretrained/mit_b1.pth',
    backbone=dict(type='mit_b1', style='pytorch'),
    decode_head=dict(
        type='SegFormerHead',
        in_channels=[64, 128, 320, 512],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=128,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=False,
        decoder_params=dict(embed_dim=256),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
        upsample_mode='fade_fuse_124'),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'data/ade/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='AlignedResize', keep_ratio=True, size_divisor=32),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=4,
    train=dict(
        type='RepeatDataset',
        times=50,
        dataset=dict(
            type='ADE20KDataset',
            data_root='data/ade/ADEChallengeData2016',
            img_dir='images/training',
            ann_dir='annotations/training',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', reduce_zero_label=True),
                dict(
                    type='Resize',
                    img_scale=(2048, 512),
                    ratio_range=(0.5, 2.0)),
                dict(
                    type='RandomCrop',
                    crop_size=(512, 512),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(type='PhotoMetricDistortion'),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ])),
    val=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(
                        type='AlignedResize', keep_ratio=True,
                        size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(
                        type='AlignedResize', keep_ratio=True,
                        size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=100)
evaluation = dict(interval=16000, metric='mIoU')
work_dir = './work_dirs/segformer.b1_fade_fuse_124.512x512.ade.160k'
gpu_ids = range(0, 1)

2022-03-09 20:06:04,362 - mmseg - INFO - Use load_from_local loader
2022-03-09 20:06:04,446 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: head.weight, head.bias

2022-03-09 20:06:04,451 - mmseg - INFO - EncoderDecoder(
  (backbone): mit_b1(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): SegFormerHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(128, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (linear_c4): MLP(
      (proj): Linear(in_features=512, out_features=256, bias=True)
    )
    (linear_c3): MLP(
      (proj): Linear(in_features=320, out_features=256, bias=True)
    )
    (linear_c2): MLP(
      (proj): Linear(in_features=128, out_features=256, bias=True)
    )
    (linear_c1): MLP(
      (proj): Linear(in_features=64, out_features=256, bias=True)
    )
    (linear_fuse): ConvModule(
      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (upsamplers): ModuleList(
      (0): FadeUp(
        (selector): Selector(
          (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
        )
        (up): FuseOF(
          (conv1_g): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
          (conv1_x): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): FadeUp(
        (selector): Selector(
          (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
        )
        (up): FuseOF(
          (conv1_g): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
          (conv1_x): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (2): FadeUp(
        (selector): Selector(
          (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
        )
        (up): FuseOF(
          (conv1_g): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
          (conv1_x): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (3): FadeUp(
        (selector): Selector(
          (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
        )
        (up): FuseOF(
          (conv1_g): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
          (conv1_x): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (4): FadeUp(
        (selector): Selector(
          (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
        )
        (up): FuseOF(
          (conv1_g): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
          (conv1_x): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (5): FadeUp(
        (selector): Selector(
          (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
        )
        (up): FuseOF(
          (conv1_g): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
          (conv1_x): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (linear_pred): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
  )
)
2022-03-09 20:06:04,968 - mmseg - INFO - Loaded 20210 images
2022-03-09 20:06:11,159 - mmseg - INFO - Loaded 2000 images
2022-03-09 20:06:11,161 - mmseg - INFO - Start running, host: yezixuan@amax, work_dir: /data/yezixuan/PycharmProjects/SegFormer/work_dirs/segformer.b1_fade_fuse_124.512x512.ade.160k
2022-03-09 20:06:11,161 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2022-03-09 20:07:30,180 - mmseg - INFO - Iter [50/160000]	lr: 1.959e-06, eta: 2 days, 21:46:44, time: 1.571, data_time: 0.030, memory: 21676, decode.loss_seg: 4.0894, decode.acc_seg: 0.3976, loss: 4.0894
2022-03-09 20:08:42,475 - mmseg - INFO - Saving checkpoint at 100 iterations
2022-03-09 20:08:43,574 - mmseg - INFO - Iter [100/160000]	lr: 3.958e-06, eta: 2 days, 19:28:51, time: 1.468, data_time: 0.017, memory: 21676, decode.loss_seg: 3.9935, decode.acc_seg: 5.4934, loss: 3.9935
2022-03-09 20:09:52,565 - mmseg - INFO - Iter [150/160000]	lr: 5.955e-06, eta: 2 days, 17:23:45, time: 1.380, data_time: 0.016, memory: 21676, decode.loss_seg: 3.4978, decode.acc_seg: 21.1752, loss: 3.4978
2022-03-09 20:11:04,615 - mmseg - INFO - Saving checkpoint at 200 iterations
2022-03-09 20:11:05,709 - mmseg - INFO - Iter [200/160000]	lr: 7.950e-06, eta: 2 days, 17:15:54, time: 1.463, data_time: 0.018, memory: 21676, decode.loss_seg: 2.8310, decode.acc_seg: 32.0697, loss: 2.8310
2022-03-09 20:12:17,433 - mmseg - INFO - Iter [250/160000]	lr: 9.945e-06, eta: 2 days, 16:55:35, time: 1.434, data_time: 0.019, memory: 21676, decode.loss_seg: 2.3616, decode.acc_seg: 36.7608, loss: 2.3616
2022-03-09 20:13:29,919 - mmseg - INFO - Saving checkpoint at 300 iterations
2022-03-09 20:13:31,003 - mmseg - INFO - Iter [300/160000]	lr: 1.194e-05, eta: 2 days, 16:58:01, time: 1.471, data_time: 0.018, memory: 21676, decode.loss_seg: 2.0665, decode.acc_seg: 39.8061, loss: 2.0665
2022-03-09 20:14:42,060 - mmseg - INFO - Iter [350/160000]	lr: 1.393e-05, eta: 2 days, 16:40:19, time: 1.421, data_time: 0.019, memory: 21676, decode.loss_seg: 1.9304, decode.acc_seg: 41.4906, loss: 1.9304
2022-03-09 20:15:56,449 - mmseg - INFO - Saving checkpoint at 400 iterations
2022-03-09 20:15:57,546 - mmseg - INFO - Iter [400/160000]	lr: 1.592e-05, eta: 2 days, 16:56:11, time: 1.510, data_time: 0.019, memory: 21676, decode.loss_seg: 1.7943, decode.acc_seg: 42.3752, loss: 1.7943
2022-03-09 20:17:12,710 - mmseg - INFO - Iter [450/160000]	lr: 1.791e-05, eta: 2 days, 17:06:21, time: 1.503, data_time: 0.018, memory: 21676, decode.loss_seg: 1.6025, decode.acc_seg: 45.8425, loss: 1.6025
2022-03-09 20:18:27,782 - mmseg - INFO - Saving checkpoint at 500 iterations
2022-03-09 20:18:28,908 - mmseg - INFO - Iter [500/160000]	lr: 1.990e-05, eta: 2 days, 17:19:43, time: 1.524, data_time: 0.018, memory: 21676, decode.loss_seg: 1.5857, decode.acc_seg: 47.6074, loss: 1.5857
2022-03-09 20:19:43,838 - mmseg - INFO - Iter [550/160000]	lr: 2.188e-05, eta: 2 days, 17:24:19, time: 1.499, data_time: 0.019, memory: 21676, decode.loss_seg: 1.4929, decode.acc_seg: 49.6418, loss: 1.4929
2022-03-09 20:20:59,358 - mmseg - INFO - Saving checkpoint at 600 iterations
2022-03-09 20:21:00,538 - mmseg - INFO - Iter [600/160000]	lr: 2.387e-05, eta: 2 days, 17:35:46, time: 1.534, data_time: 0.017, memory: 21676, decode.loss_seg: 1.4864, decode.acc_seg: 46.3554, loss: 1.4864
2022-03-09 20:22:16,140 - mmseg - INFO - Iter [650/160000]	lr: 2.585e-05, eta: 2 days, 17:40:46, time: 1.512, data_time: 0.018, memory: 21676, decode.loss_seg: 1.3752, decode.acc_seg: 49.4410, loss: 1.3752
2022-03-09 20:23:32,197 - mmseg - INFO - Saving checkpoint at 700 iterations
2022-03-09 20:23:33,364 - mmseg - INFO - Iter [700/160000]	lr: 2.784e-05, eta: 2 days, 17:51:02, time: 1.544, data_time: 0.019, memory: 21676, decode.loss_seg: 1.3622, decode.acc_seg: 49.7422, loss: 1.3622
2022-03-09 20:24:49,493 - mmseg - INFO - Iter [750/160000]	lr: 2.982e-05, eta: 2 days, 17:55:53, time: 1.523, data_time: 0.018, memory: 21676, decode.loss_seg: 1.3084, decode.acc_seg: 50.7327, loss: 1.3084
2022-03-09 20:26:05,271 - mmseg - INFO - Saving checkpoint at 800 iterations
2022-03-09 20:26:06,304 - mmseg - INFO - Iter [800/160000]	lr: 3.180e-05, eta: 2 days, 18:02:14, time: 1.536, data_time: 0.018, memory: 21676, decode.loss_seg: 1.3330, decode.acc_seg: 49.4971, loss: 1.3330
2022-03-09 20:27:13,079 - mmseg - INFO - Iter [850/160000]	lr: 3.378e-05, eta: 2 days, 17:36:22, time: 1.335, data_time: 0.017, memory: 21676, decode.loss_seg: 1.2468, decode.acc_seg: 50.9368, loss: 1.2468
2022-03-09 20:28:28,357 - mmseg - INFO - Saving checkpoint at 900 iterations
2022-03-09 20:28:29,481 - mmseg - INFO - Iter [900/160000]	lr: 3.576e-05, eta: 2 days, 17:41:36, time: 1.528, data_time: 0.017, memory: 21676, decode.loss_seg: 1.2408, decode.acc_seg: 49.9467, loss: 1.2408
2022-03-09 20:29:45,258 - mmseg - INFO - Iter [950/160000]	lr: 3.773e-05, eta: 2 days, 17:44:25, time: 1.515, data_time: 0.018, memory: 21676, decode.loss_seg: 1.2069, decode.acc_seg: 51.5829, loss: 1.2069
2022-03-09 20:31:00,623 - mmseg - INFO - Saving checkpoint at 1000 iterations
2022-03-09 20:31:01,755 - mmseg - INFO - Exp name: segformer.b1_fade_fuse_124.512x512.ade.160k.py
2022-03-09 20:31:01,755 - mmseg - INFO - Iter [1000/160000]	lr: 3.971e-05, eta: 2 days, 17:48:44, time: 1.530, data_time: 0.018, memory: 21676, decode.loss_seg: 1.2037, decode.acc_seg: 51.3680, loss: 1.2037
2022-03-09 20:32:13,810 - mmseg - INFO - Iter [1050/160000]	lr: 4.168e-05, eta: 2 days, 17:41:19, time: 1.441, data_time: 0.017, memory: 21676, decode.loss_seg: 1.1721, decode.acc_seg: 51.6138, loss: 1.1721
2022-03-09 20:33:25,973 - mmseg - INFO - Saving checkpoint at 1100 iterations
2022-03-09 20:33:27,014 - mmseg - INFO - Iter [1100/160000]	lr: 4.366e-05, eta: 2 days, 17:37:13, time: 1.464, data_time: 0.016, memory: 21676, decode.loss_seg: 1.1812, decode.acc_seg: 51.4679, loss: 1.1812
2022-03-09 20:34:34,892 - mmseg - INFO - Iter [1150/160000]	lr: 4.563e-05, eta: 2 days, 17:21:07, time: 1.358, data_time: 0.016, memory: 21676, decode.loss_seg: 1.1609, decode.acc_seg: 52.5591, loss: 1.1609
2022-03-09 20:35:49,678 - mmseg - INFO - Saving checkpoint at 1200 iterations
2022-03-09 20:35:50,809 - mmseg - INFO - Iter [1200/160000]	lr: 4.760e-05, eta: 2 days, 17:23:59, time: 1.518, data_time: 0.016, memory: 21676, decode.loss_seg: 1.1468, decode.acc_seg: 50.9675, loss: 1.1468
2022-03-09 20:37:04,593 - mmseg - INFO - Iter [1250/160000]	lr: 4.957e-05, eta: 2 days, 17:22:01, time: 1.476, data_time: 0.017, memory: 21676, decode.loss_seg: 1.1640, decode.acc_seg: 51.2444, loss: 1.1640
2022-03-09 20:38:18,795 - mmseg - INFO - Saving checkpoint at 1300 iterations
2022-03-09 20:38:19,869 - mmseg - INFO - Iter [1300/160000]	lr: 5.154e-05, eta: 2 days, 17:23:08, time: 1.506, data_time: 0.017, memory: 21676, decode.loss_seg: 1.0957, decode.acc_seg: 53.6191, loss: 1.0957
2022-03-09 20:39:34,693 - mmseg - INFO - Iter [1350/160000]	lr: 5.351e-05, eta: 2 days, 17:23:12, time: 1.496, data_time: 0.019, memory: 21676, decode.loss_seg: 1.0591, decode.acc_seg: 53.6253, loss: 1.0591
2022-03-09 20:40:46,224 - mmseg - INFO - Saving checkpoint at 1400 iterations
2022-03-09 20:40:47,321 - mmseg - INFO - Iter [1400/160000]	lr: 5.547e-05, eta: 2 days, 17:19:01, time: 1.453, data_time: 0.018, memory: 21676, decode.loss_seg: 1.0828, decode.acc_seg: 52.5173, loss: 1.0828
2022-03-09 20:41:49,705 - mmseg - INFO - Iter [1450/160000]	lr: 5.744e-05, eta: 2 days, 16:56:22, time: 1.248, data_time: 0.016, memory: 21676, decode.loss_seg: 1.0725, decode.acc_seg: 52.8178, loss: 1.0725
2022-03-09 20:43:03,437 - mmseg - INFO - Saving checkpoint at 1500 iterations
2022-03-09 20:43:04,549 - mmseg - INFO - Iter [1500/160000]	lr: 5.940e-05, eta: 2 days, 16:57:07, time: 1.497, data_time: 0.018, memory: 21676, decode.loss_seg: 1.0790, decode.acc_seg: 52.7385, loss: 1.0790
2022-03-09 20:44:17,910 - mmseg - INFO - Iter [1550/160000]	lr: 5.942e-05, eta: 2 days, 16:55:12, time: 1.467, data_time: 0.018, memory: 21676, decode.loss_seg: 1.0386, decode.acc_seg: 52.1300, loss: 1.0386
2022-03-09 20:45:28,775 - mmseg - INFO - Saving checkpoint at 1600 iterations
2022-03-09 20:45:29,104 - mmseg - INFO - Iter [1600/160000]	lr: 5.940e-05, eta: 2 days, 16:49:45, time: 1.424, data_time: 0.017, memory: 21676, decode.loss_seg: 1.0115, decode.acc_seg: 54.8799, loss: 1.0115
2022-03-09 20:46:29,471 - mmseg - INFO - Iter [1650/160000]	lr: 5.938e-05, eta: 2 days, 16:27:14, time: 1.207, data_time: 0.016, memory: 21676, decode.loss_seg: 0.9638, decode.acc_seg: 54.9261, loss: 0.9638
2022-03-09 20:47:42,997 - mmseg - INFO - Saving checkpoint at 1700 iterations
2022-03-09 20:47:43,426 - mmseg - INFO - Iter [1700/160000]	lr: 5.936e-05, eta: 2 days, 16:27:05, time: 1.479, data_time: 0.018, memory: 21676, decode.loss_seg: 1.0727, decode.acc_seg: 53.8298, loss: 1.0727
2022-03-09 20:48:58,261 - mmseg - INFO - Iter [1750/160000]	lr: 5.934e-05, eta: 2 days, 16:28:12, time: 1.497, data_time: 0.018, memory: 21676, decode.loss_seg: 1.0737, decode.acc_seg: 53.5589, loss: 1.0737
2022-03-09 20:50:13,281 - mmseg - INFO - Saving checkpoint at 1800 iterations
2022-03-09 20:50:13,632 - mmseg - INFO - Iter [1800/160000]	lr: 5.933e-05, eta: 2 days, 16:29:58, time: 1.507, data_time: 0.018, memory: 21676, decode.loss_seg: 0.9784, decode.acc_seg: 53.5950, loss: 0.9784
2022-03-09 20:51:29,283 - mmseg - INFO - Iter [1850/160000]	lr: 5.931e-05, eta: 2 days, 16:31:58, time: 1.513, data_time: 0.019, memory: 21676, decode.loss_seg: 1.0308, decode.acc_seg: 53.1483, loss: 1.0308
2022-03-09 20:52:44,377 - mmseg - INFO - Saving checkpoint at 1900 iterations
2022-03-09 20:52:44,721 - mmseg - INFO - Iter [1900/160000]	lr: 5.929e-05, eta: 2 days, 16:33:30, time: 1.509, data_time: 0.018, memory: 21676, decode.loss_seg: 0.9566, decode.acc_seg: 56.1589, loss: 0.9566
2022-03-09 20:54:00,182 - mmseg - INFO - Iter [1950/160000]	lr: 5.927e-05, eta: 2 days, 16:34:55, time: 1.509, data_time: 0.019, memory: 21676, decode.loss_seg: 0.9627, decode.acc_seg: 53.5935, loss: 0.9627
2022-03-09 20:55:15,500 - mmseg - INFO - Saving checkpoint at 2000 iterations
2022-03-09 20:55:16,587 - mmseg - INFO - Exp name: segformer.b1_fade_fuse_124.512x512.ade.160k.py
2022-03-09 20:55:16,587 - mmseg - INFO - Iter [2000/160000]	lr: 5.925e-05, eta: 2 days, 16:37:27, time: 1.528, data_time: 0.018, memory: 21676, decode.loss_seg: 0.9301, decode.acc_seg: 54.6266, loss: 0.9301
2022-03-09 20:56:31,726 - mmseg - INFO - Iter [2050/160000]	lr: 5.923e-05, eta: 2 days, 16:38:10, time: 1.503, data_time: 0.017, memory: 21676, decode.loss_seg: 0.9311, decode.acc_seg: 54.3700, loss: 0.9311
2022-03-09 20:57:46,696 - mmseg - INFO - Saving checkpoint at 2100 iterations
2022-03-09 20:57:47,027 - mmseg - INFO - Iter [2100/160000]	lr: 5.921e-05, eta: 2 days, 16:39:00, time: 1.506, data_time: 0.018, memory: 21676, decode.loss_seg: 0.9501, decode.acc_seg: 54.8022, loss: 0.9501
2022-03-09 20:59:02,457 - mmseg - INFO - Iter [2150/160000]	lr: 5.919e-05, eta: 2 days, 16:39:53, time: 1.509, data_time: 0.018, memory: 21676, decode.loss_seg: 0.9506, decode.acc_seg: 55.0719, loss: 0.9506
2022-03-09 21:00:17,376 - mmseg - INFO - Saving checkpoint at 2200 iterations
2022-03-09 21:00:17,797 - mmseg - INFO - Iter [2200/160000]	lr: 5.918e-05, eta: 2 days, 16:40:34, time: 1.507, data_time: 0.018, memory: 21676, decode.loss_seg: 0.9218, decode.acc_seg: 55.6552, loss: 0.9218
2022-03-09 21:01:32,991 - mmseg - INFO - Iter [2250/160000]	lr: 5.916e-05, eta: 2 days, 16:41:00, time: 1.504, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8813, decode.acc_seg: 53.9325, loss: 0.8813
2022-03-09 21:02:47,323 - mmseg - INFO - Saving checkpoint at 2300 iterations
2022-03-09 21:02:47,693 - mmseg - INFO - Iter [2300/160000]	lr: 5.914e-05, eta: 2 days, 16:40:47, time: 1.494, data_time: 0.018, memory: 21676, decode.loss_seg: 0.9259, decode.acc_seg: 55.5438, loss: 0.9259
2022-03-09 21:04:01,625 - mmseg - INFO - Iter [2350/160000]	lr: 5.912e-05, eta: 2 days, 16:39:41, time: 1.479, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8905, decode.acc_seg: 54.9621, loss: 0.8905
2022-03-09 21:05:16,234 - mmseg - INFO - Saving checkpoint at 2400 iterations
2022-03-09 21:05:16,558 - mmseg - INFO - Iter [2400/160000]	lr: 5.910e-05, eta: 2 days, 16:39:39, time: 1.499, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8967, decode.acc_seg: 55.5821, loss: 0.8967
2022-03-09 21:06:30,956 - mmseg - INFO - Iter [2450/160000]	lr: 5.908e-05, eta: 2 days, 16:39:01, time: 1.488, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8642, decode.acc_seg: 57.4582, loss: 0.8642
2022-03-09 21:07:35,449 - mmseg - INFO - Saving checkpoint at 2500 iterations
2022-03-09 21:07:36,579 - mmseg - INFO - Iter [2500/160000]	lr: 5.906e-05, eta: 2 days, 16:29:08, time: 1.312, data_time: 0.017, memory: 21676, decode.loss_seg: 0.9197, decode.acc_seg: 55.2840, loss: 0.9197
2022-03-09 21:08:34,097 - mmseg - INFO - Iter [2550/160000]	lr: 5.904e-05, eta: 2 days, 16:11:15, time: 1.150, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8727, decode.acc_seg: 55.8313, loss: 0.8727
2022-03-09 21:09:49,309 - mmseg - INFO - Saving checkpoint at 2600 iterations
2022-03-09 21:09:49,663 - mmseg - INFO - Iter [2600/160000]	lr: 5.903e-05, eta: 2 days, 16:12:14, time: 1.511, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8587, decode.acc_seg: 57.7983, loss: 0.8587
2022-03-09 21:11:04,309 - mmseg - INFO - Iter [2650/160000]	lr: 5.901e-05, eta: 2 days, 16:12:13, time: 1.493, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8906, decode.acc_seg: 55.4145, loss: 0.8906
2022-03-09 21:12:19,388 - mmseg - INFO - Saving checkpoint at 2700 iterations
2022-03-09 21:12:19,797 - mmseg - INFO - Iter [2700/160000]	lr: 5.899e-05, eta: 2 days, 16:12:58, time: 1.510, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8731, decode.acc_seg: 56.4465, loss: 0.8731
2022-03-09 21:13:31,462 - mmseg - INFO - Iter [2750/160000]	lr: 5.897e-05, eta: 2 days, 16:10:01, time: 1.433, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8866, decode.acc_seg: 55.4299, loss: 0.8866
2022-03-09 21:14:46,177 - mmseg - INFO - Saving checkpoint at 2800 iterations
2022-03-09 21:14:46,533 - mmseg - INFO - Iter [2800/160000]	lr: 5.895e-05, eta: 2 days, 16:10:18, time: 1.501, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8552, decode.acc_seg: 57.6967, loss: 0.8552
2022-03-09 21:16:00,777 - mmseg - INFO - Iter [2850/160000]	lr: 5.893e-05, eta: 2 days, 16:09:47, time: 1.485, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8486, decode.acc_seg: 56.7880, loss: 0.8486
2022-03-09 21:17:09,985 - mmseg - INFO - Saving checkpoint at 2900 iterations
2022-03-09 21:17:10,324 - mmseg - INFO - Iter [2900/160000]	lr: 5.891e-05, eta: 2 days, 16:05:00, time: 1.391, data_time: 0.017, memory: 21676, decode.loss_seg: 0.9143, decode.acc_seg: 54.8292, loss: 0.9143
2022-03-09 21:18:17,172 - mmseg - INFO - Iter [2950/160000]	lr: 5.889e-05, eta: 2 days, 15:57:56, time: 1.337, data_time: 0.016, memory: 21676, decode.loss_seg: 0.9404, decode.acc_seg: 54.8220, loss: 0.9404
2022-03-09 21:19:31,129 - mmseg - INFO - Saving checkpoint at 3000 iterations
2022-03-09 21:19:32,151 - mmseg - INFO - Exp name: segformer.b1_fade_fuse_124.512x512.ade.160k.py
2022-03-09 21:19:32,151 - mmseg - INFO - Iter [3000/160000]	lr: 5.888e-05, eta: 2 days, 15:58:10, time: 1.500, data_time: 0.018, memory: 21676, decode.loss_seg: 0.9372, decode.acc_seg: 56.2461, loss: 0.9372
2022-03-09 21:20:34,137 - mmseg - INFO - Iter [3050/160000]	lr: 5.886e-05, eta: 2 days, 15:47:12, time: 1.240, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8784, decode.acc_seg: 56.2138, loss: 0.8784
2022-03-09 21:21:49,278 - mmseg - INFO - Saving checkpoint at 3100 iterations
2022-03-09 21:21:49,620 - mmseg - INFO - Iter [3100/160000]	lr: 5.884e-05, eta: 2 days, 15:47:57, time: 1.510, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8823, decode.acc_seg: 55.3964, loss: 0.8823
2022-03-09 21:22:59,591 - mmseg - INFO - Iter [3150/160000]	lr: 5.882e-05, eta: 2 days, 15:44:03, time: 1.399, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8137, decode.acc_seg: 56.9220, loss: 0.8137
2022-03-09 21:24:00,235 - mmseg - INFO - Saving checkpoint at 3200 iterations
2022-03-09 21:24:00,563 - mmseg - INFO - Iter [3200/160000]	lr: 5.880e-05, eta: 2 days, 15:32:54, time: 1.219, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8442, decode.acc_seg: 57.4426, loss: 0.8442
2022-03-09 21:25:10,269 - mmseg - INFO - Iter [3250/160000]	lr: 5.878e-05, eta: 2 days, 15:29:04, time: 1.394, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8697, decode.acc_seg: 57.0678, loss: 0.8697
2022-03-09 21:26:20,807 - mmseg - INFO - Saving checkpoint at 3300 iterations
2022-03-09 21:26:21,228 - mmseg - INFO - Iter [3300/160000]	lr: 5.876e-05, eta: 2 days, 15:26:19, time: 1.419, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8686, decode.acc_seg: 57.9284, loss: 0.8686
2022-03-09 21:27:30,860 - mmseg - INFO - Iter [3350/160000]	lr: 5.874e-05, eta: 2 days, 15:22:35, time: 1.393, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8692, decode.acc_seg: 57.4756, loss: 0.8692
2022-03-09 21:28:44,365 - mmseg - INFO - Saving checkpoint at 3400 iterations
2022-03-09 21:28:44,688 - mmseg - INFO - Iter [3400/160000]	lr: 5.873e-05, eta: 2 days, 15:22:08, time: 1.477, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8416, decode.acc_seg: 56.8440, loss: 0.8416
2022-03-09 21:29:59,236 - mmseg - INFO - Iter [3450/160000]	lr: 5.871e-05, eta: 2 days, 15:22:13, time: 1.491, data_time: 0.019, memory: 21676, decode.loss_seg: 0.8310, decode.acc_seg: 55.7222, loss: 0.8310
2022-03-09 21:31:07,906 - mmseg - INFO - Saving checkpoint at 3500 iterations
2022-03-09 21:31:09,037 - mmseg - INFO - Iter [3500/160000]	lr: 5.869e-05, eta: 2 days, 15:18:43, time: 1.396, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8662, decode.acc_seg: 55.7434, loss: 0.8662
2022-03-09 21:32:13,083 - mmseg - INFO - Iter [3550/160000]	lr: 5.867e-05, eta: 2 days, 15:11:04, time: 1.281, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8446, decode.acc_seg: 56.1754, loss: 0.8446
2022-03-09 21:33:22,381 - mmseg - INFO - Saving checkpoint at 3600 iterations
2022-03-09 21:33:22,714 - mmseg - INFO - Iter [3600/160000]	lr: 5.865e-05, eta: 2 days, 15:07:38, time: 1.393, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8614, decode.acc_seg: 55.9662, loss: 0.8614
2022-03-09 21:34:36,293 - mmseg - INFO - Iter [3650/160000]	lr: 5.863e-05, eta: 2 days, 15:07:05, time: 1.472, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8786, decode.acc_seg: 56.4724, loss: 0.8786
2022-03-09 21:35:47,584 - mmseg - INFO - Saving checkpoint at 3700 iterations
2022-03-09 21:35:47,948 - mmseg - INFO - Iter [3700/160000]	lr: 5.861e-05, eta: 2 days, 15:05:09, time: 1.433, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8208, decode.acc_seg: 58.6105, loss: 0.8208
2022-03-09 21:36:35,186 - mmseg - INFO - Iter [3750/160000]	lr: 5.859e-05, eta: 2 days, 14:46:18, time: 0.945, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8122, decode.acc_seg: 57.6476, loss: 0.8122
2022-03-09 21:37:48,919 - mmseg - INFO - Saving checkpoint at 3800 iterations
2022-03-09 21:37:49,253 - mmseg - INFO - Iter [3800/160000]	lr: 5.858e-05, eta: 2 days, 14:46:18, time: 1.481, data_time: 0.017, memory: 21676, decode.loss_seg: 0.8312, decode.acc_seg: 58.8378, loss: 0.8312
2022-03-09 21:39:03,147 - mmseg - INFO - Iter [3850/160000]	lr: 5.856e-05, eta: 2 days, 14:46:08, time: 1.478, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8025, decode.acc_seg: 57.8198, loss: 0.8025
2022-03-09 21:40:14,035 - mmseg - INFO - Saving checkpoint at 3900 iterations
2022-03-09 21:40:14,362 - mmseg - INFO - Iter [3900/160000]	lr: 5.854e-05, eta: 2 days, 14:44:10, time: 1.424, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8538, decode.acc_seg: 58.1138, loss: 0.8538
2022-03-09 21:41:20,156 - mmseg - INFO - Iter [3950/160000]	lr: 5.852e-05, eta: 2 days, 14:38:39, time: 1.316, data_time: 0.016, memory: 21676, decode.loss_seg: 0.8289, decode.acc_seg: 57.0665, loss: 0.8289
2022-03-09 21:42:34,089 - mmseg - INFO - Saving checkpoint at 4000 iterations
2022-03-09 21:42:35,311 - mmseg - INFO - Exp name: segformer.b1_fade_fuse_124.512x512.ade.160k.py
2022-03-09 21:42:35,311 - mmseg - INFO - Iter [4000/160000]	lr: 5.850e-05, eta: 2 days, 14:39:20, time: 1.503, data_time: 0.018, memory: 21676, decode.loss_seg: 0.8348, decode.acc_seg: 57.4278, loss: 0.8348
