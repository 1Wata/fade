2022-03-09 14:40:12,408 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]
CUDA available: True
GPU 0,1: RTX A6000
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.1.TC455_06.29069683_0
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.9.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.10.0
OpenCV: 4.5.3
MMCV: 1.2.7
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.1
MMSegmentation: 0.11.0+
------------------------------------------------------------

2022-03-09 14:40:12,408 - mmseg - INFO - Distributed training: False
2022-03-09 14:40:12,653 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
find_unused_parameters = True
model = dict(
    type='EncoderDecoder',
    pretrained='pretrained/mit_b1.pth',
    backbone=dict(type='mit_b1', style='pytorch'),
    decode_head=dict(
        type='SegFormerHead',
        in_channels=[64, 128, 320, 512],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=128,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=False,
        decoder_params=dict(embed_dim=256),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
        upsample_mode='carafe'),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'data/ade/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='AlignedResize', keep_ratio=True, size_divisor=32),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=4,
    train=dict(
        type='RepeatDataset',
        times=50,
        dataset=dict(
            type='ADE20KDataset',
            data_root='data/ade/ADEChallengeData2016',
            img_dir='images/training',
            ann_dir='annotations/training',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', reduce_zero_label=True),
                dict(
                    type='Resize',
                    img_scale=(2048, 512),
                    ratio_range=(0.5, 2.0)),
                dict(
                    type='RandomCrop',
                    crop_size=(512, 512),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(type='PhotoMetricDistortion'),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ])),
    val=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(
                        type='AlignedResize', keep_ratio=True,
                        size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(
                        type='AlignedResize', keep_ratio=True,
                        size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=10)
evaluation = dict(interval=16000, metric='mIoU')
work_dir = './work_dirs/segformer.b1_carafe.512x512.ade.160k'
gpu_ids = range(0, 1)

2022-03-09 14:40:13,667 - mmseg - INFO - Use load_from_local loader
2022-03-09 14:40:14,382 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: head.weight, head.bias

2022-03-09 14:40:14,387 - mmseg - INFO - EncoderDecoder(
  (backbone): mit_b1(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): SegFormerHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(128, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (linear_c4): MLP(
      (proj): Linear(in_features=512, out_features=256, bias=True)
    )
    (linear_c3): MLP(
      (proj): Linear(in_features=320, out_features=256, bias=True)
    )
    (linear_c2): MLP(
      (proj): Linear(in_features=128, out_features=256, bias=True)
    )
    (linear_c1): MLP(
      (proj): Linear(in_features=64, out_features=256, bias=True)
    )
    (linear_fuse): ConvModule(
      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (upsamplers): ModuleList(
      (0): CARAFEPack(
        (channel_compressor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (content_encoder): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): CARAFEPack(
        (channel_compressor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (content_encoder): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): CARAFEPack(
        (channel_compressor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (content_encoder): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): CARAFEPack(
        (channel_compressor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (content_encoder): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (4): CARAFEPack(
        (channel_compressor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (content_encoder): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (5): CARAFEPack(
        (channel_compressor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (content_encoder): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (linear_pred): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
  )
)
2022-03-09 14:40:14,863 - mmseg - INFO - Loaded 20210 images
2022-03-09 14:40:28,560 - mmseg - INFO - Loaded 2000 images
2022-03-09 14:40:28,561 - mmseg - INFO - Start running, host: yezixuan@amax, work_dir: /data/yezixuan/PycharmProjects/SegFormer/work_dirs/segformer.b1_carafe.512x512.ade.160k
2022-03-09 14:40:28,561 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2022-03-09 14:40:46,976 - mmseg - INFO - Saving checkpoint at 10 iterations
2022-03-09 14:41:00,023 - mmseg - INFO - Saving checkpoint at 20 iterations
2022-03-09 14:41:13,295 - mmseg - INFO - Saving checkpoint at 30 iterations
2022-03-09 14:41:26,468 - mmseg - INFO - Saving checkpoint at 40 iterations
2022-03-09 14:41:38,578 - mmseg - INFO - Saving checkpoint at 50 iterations
2022-03-09 14:41:38,938 - mmseg - INFO - Iter [50/160000]	lr: 1.959e-06, eta: 2 days, 14:09:07, time: 1.399, data_time: 0.029, memory: 19400, decode.loss_seg: 4.1369, decode.acc_seg: 0.3234, loss: 4.1369
2022-03-09 14:41:48,832 - mmseg - INFO - Saving checkpoint at 60 iterations
2022-03-09 14:42:02,354 - mmseg - INFO - Saving checkpoint at 70 iterations
2022-03-09 14:42:14,496 - mmseg - INFO - Saving checkpoint at 80 iterations
2022-03-09 14:42:26,222 - mmseg - INFO - Saving checkpoint at 90 iterations
2022-03-09 14:42:39,791 - mmseg - INFO - Saving checkpoint at 100 iterations
2022-03-09 14:42:40,141 - mmseg - INFO - Iter [100/160000]	lr: 3.958e-06, eta: 2 days, 10:15:01, time: 1.224, data_time: 0.017, memory: 19400, decode.loss_seg: 3.9816, decode.acc_seg: 2.7022, loss: 3.9816
2022-03-09 14:42:53,356 - mmseg - INFO - Saving checkpoint at 110 iterations
2022-03-09 14:43:06,736 - mmseg - INFO - Saving checkpoint at 120 iterations
2022-03-09 14:43:19,814 - mmseg - INFO - Saving checkpoint at 130 iterations
2022-03-09 14:43:33,367 - mmseg - INFO - Saving checkpoint at 140 iterations
2022-03-09 14:43:46,527 - mmseg - INFO - Saving checkpoint at 150 iterations
2022-03-09 14:43:46,924 - mmseg - INFO - Iter [150/160000]	lr: 5.955e-06, eta: 2 days, 10:35:24, time: 1.336, data_time: 0.016, memory: 19400, decode.loss_seg: 3.5572, decode.acc_seg: 19.8625, loss: 3.5572
2022-03-09 14:43:59,761 - mmseg - INFO - Saving checkpoint at 160 iterations
2022-03-09 14:44:12,905 - mmseg - INFO - Saving checkpoint at 170 iterations
2022-03-09 14:44:26,152 - mmseg - INFO - Saving checkpoint at 180 iterations
2022-03-09 14:44:39,529 - mmseg - INFO - Saving checkpoint at 190 iterations
2022-03-09 14:44:52,779 - mmseg - INFO - Saving checkpoint at 200 iterations
2022-03-09 14:44:53,137 - mmseg - INFO - Iter [200/160000]	lr: 7.950e-06, eta: 2 days, 10:37:28, time: 1.324, data_time: 0.018, memory: 19400, decode.loss_seg: 2.9780, decode.acc_seg: 34.1316, loss: 2.9780
2022-03-09 14:45:05,945 - mmseg - INFO - Saving checkpoint at 210 iterations
2022-03-09 14:45:19,131 - mmseg - INFO - Saving checkpoint at 220 iterations
2022-03-09 14:45:32,567 - mmseg - INFO - Saving checkpoint at 230 iterations
2022-03-09 14:45:45,813 - mmseg - INFO - Saving checkpoint at 240 iterations
2022-03-09 14:45:58,989 - mmseg - INFO - Saving checkpoint at 250 iterations
2022-03-09 14:45:59,333 - mmseg - INFO - Iter [250/160000]	lr: 9.945e-06, eta: 2 days, 10:38:04, time: 1.324, data_time: 0.017, memory: 19400, decode.loss_seg: 2.4295, decode.acc_seg: 38.6083, loss: 2.4295
2022-03-09 14:46:12,032 - mmseg - INFO - Saving checkpoint at 260 iterations
2022-03-09 14:46:25,080 - mmseg - INFO - Saving checkpoint at 270 iterations
2022-03-09 14:46:37,362 - mmseg - INFO - Saving checkpoint at 280 iterations
2022-03-09 14:46:50,132 - mmseg - INFO - Saving checkpoint at 290 iterations
2022-03-09 14:47:03,627 - mmseg - INFO - Saving checkpoint at 300 iterations
2022-03-09 14:47:03,971 - mmseg - INFO - Iter [300/160000]	lr: 1.194e-05, eta: 2 days, 10:24:16, time: 1.293, data_time: 0.016, memory: 19400, decode.loss_seg: 2.1435, decode.acc_seg: 41.0751, loss: 2.1435
2022-03-09 14:47:16,871 - mmseg - INFO - Saving checkpoint at 310 iterations
2022-03-09 14:47:30,014 - mmseg - INFO - Saving checkpoint at 320 iterations
2022-03-09 14:47:43,026 - mmseg - INFO - Saving checkpoint at 330 iterations
2022-03-09 14:47:56,124 - mmseg - INFO - Saving checkpoint at 340 iterations
2022-03-09 14:48:09,434 - mmseg - INFO - Saving checkpoint at 350 iterations
2022-03-09 14:48:09,743 - mmseg - INFO - Iter [350/160000]	lr: 1.393e-05, eta: 2 days, 10:22:45, time: 1.315, data_time: 0.017, memory: 19400, decode.loss_seg: 1.9174, decode.acc_seg: 41.8506, loss: 1.9174
2022-03-09 14:48:22,780 - mmseg - INFO - Saving checkpoint at 360 iterations
2022-03-09 14:48:36,012 - mmseg - INFO - Saving checkpoint at 370 iterations
2022-03-09 14:48:47,224 - mmseg - INFO - Saving checkpoint at 380 iterations
2022-03-09 14:49:00,590 - mmseg - INFO - Saving checkpoint at 390 iterations
2022-03-09 14:49:14,078 - mmseg - INFO - Saving checkpoint at 400 iterations
2022-03-09 14:49:14,486 - mmseg - INFO - Iter [400/160000]	lr: 1.592e-05, eta: 2 days, 10:14:29, time: 1.295, data_time: 0.018, memory: 19400, decode.loss_seg: 1.8615, decode.acc_seg: 43.2986, loss: 1.8615
2022-03-09 14:49:27,586 - mmseg - INFO - Saving checkpoint at 410 iterations
2022-03-09 14:49:40,914 - mmseg - INFO - Saving checkpoint at 420 iterations
2022-03-09 14:49:54,479 - mmseg - INFO - Saving checkpoint at 430 iterations
2022-03-09 14:50:07,735 - mmseg - INFO - Saving checkpoint at 440 iterations
2022-03-09 14:50:20,840 - mmseg - INFO - Saving checkpoint at 450 iterations
2022-03-09 14:50:21,170 - mmseg - INFO - Iter [450/160000]	lr: 1.791e-05, eta: 2 days, 10:19:16, time: 1.334, data_time: 0.018, memory: 19400, decode.loss_seg: 1.6431, decode.acc_seg: 46.7557, loss: 1.6431
2022-03-09 14:50:34,343 - mmseg - INFO - Saving checkpoint at 460 iterations
2022-03-09 14:50:47,628 - mmseg - INFO - Saving checkpoint at 470 iterations
2022-03-09 14:51:01,034 - mmseg - INFO - Saving checkpoint at 480 iterations
2022-03-09 14:51:14,305 - mmseg - INFO - Saving checkpoint at 490 iterations
2022-03-09 14:51:27,766 - mmseg - INFO - Saving checkpoint at 500 iterations
2022-03-09 14:51:28,137 - mmseg - INFO - Iter [500/160000]	lr: 1.990e-05, eta: 2 days, 10:24:23, time: 1.339, data_time: 0.016, memory: 19400, decode.loss_seg: 1.6341, decode.acc_seg: 45.2161, loss: 1.6341
2022-03-09 14:51:41,230 - mmseg - INFO - Saving checkpoint at 510 iterations
2022-03-09 14:51:54,229 - mmseg - INFO - Saving checkpoint at 520 iterations
2022-03-09 14:52:05,996 - mmseg - INFO - Saving checkpoint at 530 iterations
2022-03-09 14:52:19,456 - mmseg - INFO - Saving checkpoint at 540 iterations
2022-03-09 14:52:33,063 - mmseg - INFO - Saving checkpoint at 550 iterations
2022-03-09 14:52:33,420 - mmseg - INFO - Iter [550/160000]	lr: 2.188e-05, eta: 2 days, 10:20:14, time: 1.306, data_time: 0.017, memory: 19400, decode.loss_seg: 1.5642, decode.acc_seg: 46.8355, loss: 1.5642
2022-03-09 14:52:45,135 - mmseg - INFO - Saving checkpoint at 560 iterations
2022-03-09 14:52:56,234 - mmseg - INFO - Saving checkpoint at 570 iterations
2022-03-09 14:53:09,758 - mmseg - INFO - Saving checkpoint at 580 iterations
2022-03-09 14:53:23,457 - mmseg - INFO - Saving checkpoint at 590 iterations
2022-03-09 14:53:36,856 - mmseg - INFO - Saving checkpoint at 600 iterations
2022-03-09 14:53:37,251 - mmseg - INFO - Iter [600/160000]	lr: 2.387e-05, eta: 2 days, 10:10:10, time: 1.277, data_time: 0.017, memory: 19400, decode.loss_seg: 1.4968, decode.acc_seg: 47.0270, loss: 1.4968
2022-03-09 14:53:50,317 - mmseg - INFO - Saving checkpoint at 610 iterations
2022-03-09 14:54:03,850 - mmseg - INFO - Saving checkpoint at 620 iterations
2022-03-09 14:54:17,314 - mmseg - INFO - Saving checkpoint at 630 iterations
2022-03-09 14:54:30,593 - mmseg - INFO - Saving checkpoint at 640 iterations
2022-03-09 14:54:44,230 - mmseg - INFO - Saving checkpoint at 650 iterations
2022-03-09 14:54:44,588 - mmseg - INFO - Iter [650/160000]	lr: 2.585e-05, eta: 2 days, 10:15:49, time: 1.347, data_time: 0.017, memory: 19400, decode.loss_seg: 1.3788, decode.acc_seg: 47.1674, loss: 1.3788
2022-03-09 14:54:57,847 - mmseg - INFO - Saving checkpoint at 660 iterations
2022-03-09 14:55:11,387 - mmseg - INFO - Saving checkpoint at 670 iterations
2022-03-09 14:55:23,922 - mmseg - INFO - Saving checkpoint at 680 iterations
2022-03-09 14:55:37,410 - mmseg - INFO - Saving checkpoint at 690 iterations
2022-03-09 14:55:51,021 - mmseg - INFO - Saving checkpoint at 700 iterations
2022-03-09 14:55:51,364 - mmseg - INFO - Iter [700/160000]	lr: 2.784e-05, eta: 2 days, 10:18:22, time: 1.335, data_time: 0.018, memory: 19400, decode.loss_seg: 1.4115, decode.acc_seg: 48.3794, loss: 1.4115
2022-03-09 14:56:04,665 - mmseg - INFO - Saving checkpoint at 710 iterations
2022-03-09 14:56:18,388 - mmseg - INFO - Saving checkpoint at 720 iterations
2022-03-09 14:56:31,909 - mmseg - INFO - Saving checkpoint at 730 iterations
2022-03-09 14:56:45,694 - mmseg - INFO - Saving checkpoint at 740 iterations
2022-03-09 14:56:59,497 - mmseg - INFO - Saving checkpoint at 750 iterations
2022-03-09 14:56:59,858 - mmseg - INFO - Iter [750/160000]	lr: 2.982e-05, eta: 2 days, 10:26:30, time: 1.370, data_time: 0.016, memory: 19400, decode.loss_seg: 1.3554, decode.acc_seg: 48.5644, loss: 1.3554
2022-03-09 14:57:12,997 - mmseg - INFO - Saving checkpoint at 760 iterations
2022-03-09 14:57:25,940 - mmseg - INFO - Saving checkpoint at 770 iterations
2022-03-09 14:57:39,573 - mmseg - INFO - Saving checkpoint at 780 iterations
2022-03-09 14:57:52,750 - mmseg - INFO - Saving checkpoint at 790 iterations
2022-03-09 14:58:05,702 - mmseg - INFO - Saving checkpoint at 800 iterations
2022-03-09 14:58:06,002 - mmseg - INFO - Iter [800/160000]	lr: 3.180e-05, eta: 2 days, 10:25:42, time: 1.323, data_time: 0.017, memory: 19400, decode.loss_seg: 1.3287, decode.acc_seg: 50.6907, loss: 1.3287
2022-03-09 14:58:19,361 - mmseg - INFO - Saving checkpoint at 810 iterations
2022-03-09 14:58:32,963 - mmseg - INFO - Saving checkpoint at 820 iterations
2022-03-09 14:58:46,616 - mmseg - INFO - Saving checkpoint at 830 iterations
2022-03-09 14:59:00,479 - mmseg - INFO - Saving checkpoint at 840 iterations
2022-03-09 14:59:14,069 - mmseg - INFO - Saving checkpoint at 850 iterations
2022-03-09 14:59:14,415 - mmseg - INFO - Iter [850/160000]	lr: 3.378e-05, eta: 2 days, 10:31:55, time: 1.368, data_time: 0.016, memory: 19400, decode.loss_seg: 1.2972, decode.acc_seg: 50.6967, loss: 1.2972
2022-03-09 14:59:27,770 - mmseg - INFO - Saving checkpoint at 860 iterations
2022-03-09 14:59:41,274 - mmseg - INFO - Saving checkpoint at 870 iterations
2022-03-09 14:59:54,880 - mmseg - INFO - Saving checkpoint at 880 iterations
2022-03-09 15:00:08,409 - mmseg - INFO - Saving checkpoint at 890 iterations
2022-03-09 15:00:22,171 - mmseg - INFO - Saving checkpoint at 900 iterations
2022-03-09 15:00:22,509 - mmseg - INFO - Iter [900/160000]	lr: 3.576e-05, eta: 2 days, 10:36:24, time: 1.362, data_time: 0.017, memory: 19400, decode.loss_seg: 1.2276, decode.acc_seg: 50.2573, loss: 1.2276
2022-03-09 15:00:35,010 - mmseg - INFO - Saving checkpoint at 910 iterations
2022-03-09 15:00:48,457 - mmseg - INFO - Saving checkpoint at 920 iterations
2022-03-09 15:01:01,840 - mmseg - INFO - Saving checkpoint at 930 iterations
2022-03-09 15:01:15,392 - mmseg - INFO - Saving checkpoint at 940 iterations
2022-03-09 15:01:28,942 - mmseg - INFO - Saving checkpoint at 950 iterations
2022-03-09 15:01:29,288 - mmseg - INFO - Iter [950/160000]	lr: 3.773e-05, eta: 2 days, 10:36:37, time: 1.336, data_time: 0.017, memory: 19400, decode.loss_seg: 1.2505, decode.acc_seg: 48.4035, loss: 1.2505
2022-03-09 15:01:42,476 - mmseg - INFO - Saving checkpoint at 960 iterations
2022-03-09 15:01:56,211 - mmseg - INFO - Saving checkpoint at 970 iterations
2022-03-09 15:02:09,756 - mmseg - INFO - Saving checkpoint at 980 iterations
2022-03-09 15:02:23,334 - mmseg - INFO - Saving checkpoint at 990 iterations
2022-03-09 15:02:37,189 - mmseg - INFO - Saving checkpoint at 1000 iterations
2022-03-09 15:02:37,609 - mmseg - INFO - Exp name: segformer.b1_carafe.512x512.ade.160k.py
2022-03-09 15:02:37,609 - mmseg - INFO - Iter [1000/160000]	lr: 3.971e-05, eta: 2 days, 10:40:47, time: 1.366, data_time: 0.018, memory: 19400, decode.loss_seg: 1.1919, decode.acc_seg: 51.3177, loss: 1.1919
2022-03-09 15:02:50,835 - mmseg - INFO - Saving checkpoint at 1010 iterations
2022-03-09 15:03:04,426 - mmseg - INFO - Saving checkpoint at 1020 iterations
2022-03-09 15:03:18,028 - mmseg - INFO - Saving checkpoint at 1030 iterations
2022-03-09 15:03:31,591 - mmseg - INFO - Saving checkpoint at 1040 iterations
2022-03-09 15:03:45,153 - mmseg - INFO - Saving checkpoint at 1050 iterations
2022-03-09 15:03:45,482 - mmseg - INFO - Iter [1050/160000]	lr: 4.168e-05, eta: 2 days, 10:43:19, time: 1.357, data_time: 0.017, memory: 19400, decode.loss_seg: 1.1490, decode.acc_seg: 51.3878, loss: 1.1490
2022-03-09 15:03:58,745 - mmseg - INFO - Saving checkpoint at 1060 iterations
2022-03-09 15:04:12,400 - mmseg - INFO - Saving checkpoint at 1070 iterations
2022-03-09 15:04:25,983 - mmseg - INFO - Saving checkpoint at 1080 iterations
2022-03-09 15:04:39,655 - mmseg - INFO - Saving checkpoint at 1090 iterations
2022-03-09 15:04:53,069 - mmseg - INFO - Saving checkpoint at 1100 iterations
2022-03-09 15:04:53,379 - mmseg - INFO - Iter [1100/160000]	lr: 4.366e-05, eta: 2 days, 10:45:34, time: 1.358, data_time: 0.017, memory: 19400, decode.loss_seg: 1.1787, decode.acc_seg: 52.7538, loss: 1.1787
2022-03-09 15:05:06,637 - mmseg - INFO - Saving checkpoint at 1110 iterations
2022-03-09 15:05:20,221 - mmseg - INFO - Saving checkpoint at 1120 iterations
2022-03-09 15:05:33,842 - mmseg - INFO - Saving checkpoint at 1130 iterations
2022-03-09 15:05:47,591 - mmseg - INFO - Saving checkpoint at 1140 iterations
2022-03-09 15:06:01,401 - mmseg - INFO - Saving checkpoint at 1150 iterations
2022-03-09 15:06:01,757 - mmseg - INFO - Iter [1150/160000]	lr: 4.563e-05, eta: 2 days, 10:48:38, time: 1.368, data_time: 0.017, memory: 19400, decode.loss_seg: 1.1811, decode.acc_seg: 51.4163, loss: 1.1811
2022-03-09 15:06:14,945 - mmseg - INFO - Saving checkpoint at 1160 iterations
2022-03-09 15:06:28,556 - mmseg - INFO - Saving checkpoint at 1170 iterations
2022-03-09 15:06:42,222 - mmseg - INFO - Saving checkpoint at 1180 iterations
2022-03-09 15:06:55,665 - mmseg - INFO - Saving checkpoint at 1190 iterations
2022-03-09 15:07:08,946 - mmseg - INFO - Saving checkpoint at 1200 iterations
2022-03-09 15:07:09,286 - mmseg - INFO - Iter [1200/160000]	lr: 4.760e-05, eta: 2 days, 10:49:29, time: 1.351, data_time: 0.017, memory: 19400, decode.loss_seg: 1.1189, decode.acc_seg: 51.2096, loss: 1.1189
2022-03-09 15:07:22,437 - mmseg - INFO - Saving checkpoint at 1210 iterations
2022-03-09 15:07:35,930 - mmseg - INFO - Saving checkpoint at 1220 iterations
2022-03-09 15:07:49,493 - mmseg - INFO - Saving checkpoint at 1230 iterations
2022-03-09 15:08:03,057 - mmseg - INFO - Saving checkpoint at 1240 iterations
2022-03-09 15:08:16,543 - mmseg - INFO - Saving checkpoint at 1250 iterations
2022-03-09 15:08:16,893 - mmseg - INFO - Iter [1250/160000]	lr: 4.957e-05, eta: 2 days, 10:50:20, time: 1.352, data_time: 0.018, memory: 19400, decode.loss_seg: 1.0662, decode.acc_seg: 53.8641, loss: 1.0662
2022-03-09 15:08:29,806 - mmseg - INFO - Saving checkpoint at 1260 iterations
2022-03-09 15:08:43,271 - mmseg - INFO - Saving checkpoint at 1270 iterations
2022-03-09 15:08:56,497 - mmseg - INFO - Saving checkpoint at 1280 iterations
2022-03-09 15:09:09,821 - mmseg - INFO - Saving checkpoint at 1290 iterations
2022-03-09 15:09:23,347 - mmseg - INFO - Saving checkpoint at 1300 iterations
2022-03-09 15:09:23,775 - mmseg - INFO - Iter [1300/160000]	lr: 5.154e-05, eta: 2 days, 10:49:34, time: 1.338, data_time: 0.018, memory: 19400, decode.loss_seg: 1.1398, decode.acc_seg: 52.1128, loss: 1.1398
2022-03-09 15:09:37,167 - mmseg - INFO - Saving checkpoint at 1310 iterations
2022-03-09 15:09:50,964 - mmseg - INFO - Saving checkpoint at 1320 iterations
2022-03-09 15:10:04,230 - mmseg - INFO - Saving checkpoint at 1330 iterations
